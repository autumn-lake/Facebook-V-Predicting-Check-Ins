{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "subbbb = pd.read_csv('sub_grid0.csv')\n",
    "\n",
    "ii = df_test[df_test.grid_cell==0].index\n",
    "\n",
    "type(ii)\n",
    "\n",
    "subbbb.iloc[ii]\n",
    "\n",
    "a = pd.DataFrame(columns=list('ABC'))\n",
    "\n",
    "for i in range(800):\n",
    "    a = a.append({'A': df_train[df_train.grid_cell==i].shape[0], \n",
    "                  'B': df_test[df_test.grid_cell==i].shape[0],\n",
    "                  'C': df_train[df_train.grid_cell==i]['place_id'].unique().shape[0]},\n",
    "                  ignore_index=True)\n",
    "\n",
    "a.head()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(a['A'],a['C'])\n",
    "\n",
    "29118021.0/8607230\n",
    "\n",
    "a.to_hdf('gridinfo.h5','table')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "__author__ = 'Sandro Vega Pons : https://www.kaggle.com/svpons'\n",
    "\n",
    "'''Partially based on grid_plus_classifier script:\n",
    "https://www.kaggle.com/svpons/facebook-v-predicting-check-ins/grid-plus-classifier\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def prepare_data(df, n_cell_x, n_cell_y):\n",
    "    \"\"\"\n",
    "    Feature engineering and computation of the grid.\n",
    "    \"\"\"\n",
    "    #Creating the grid\n",
    "    size_x = 10. / n_cell_x\n",
    "    size_y = 10. / n_cell_y\n",
    "    eps = 0.00001  \n",
    "    xs = np.where(df.x.values < eps, 0, df.x.values - eps)\n",
    "    ys = np.where(df.y.values < eps, 0, df.y.values - eps)\n",
    "    pos_x = (xs / size_x).astype(np.int)\n",
    "    pos_y = (ys / size_y).astype(np.int)\n",
    "    df['grid_cell'] = (pos_y * n_cell_x + pos_x).astype(np.int16)\n",
    "    \n",
    "    #Feature engineering\n",
    "    fw = [500, 1000, 4, 3, 1./22., 2, 10] #feature weights (black magic here)\n",
    "    df.x = df.x.values * fw[0]\n",
    "    df.y = df.y.values * fw[1]\n",
    "    initial_date = np.datetime64('2014-01-01T01:01', dtype='datetime64[m]') \n",
    "    d_times = pd.DatetimeIndex(initial_date + np.timedelta64(int(mn), 'm') \n",
    "                               for mn in df.time.values)    \n",
    "    df['hour'] = (d_times.hour * fw[2]).astype(np.int8)\n",
    "    df['weekday'] = (d_times.weekday * fw[3]).astype(np.int8)\n",
    "    df['day'] = (d_times.dayofyear * fw[4]).astype(np.int8)\n",
    "    df['month'] = (d_times.month * fw[5]).astype(np.int8)\n",
    "    df['year'] = ((d_times.year - 2013) * fw[6]).astype(np.int8)\n",
    "\n",
    "    df = df.drop(['time'], axis=1) \n",
    "    return df\n",
    "    \n",
    "\n",
    "def process_one_cell(df_train, df_test, grid_id, th):\n",
    "    \"\"\"   \n",
    "    Classification inside one grid cell.\n",
    "    \"\"\"   \n",
    "    #Working on df_train\n",
    "    df_cell_train = df_train.loc[df_train.grid_cell == grid_id]\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "\n",
    "    #Working on df_test\n",
    "    df_cell_test = df_test.loc[df_test.grid_cell == grid_id]\n",
    "    row_ids = df_cell_test.index\n",
    "    \n",
    "    #Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    X = df_cell_train.drop(['place_id', 'grid_cell'], axis=1).values.astype(int)\n",
    "    X_test = df_cell_test.drop(['grid_cell'], axis = 1).values.astype(int)\n",
    "    \n",
    "    #Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=25, weights='distance', \n",
    "                               metric='manhattan',n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    pred_probas = np.sort(y_pred, axis=1)[:,::-1][:,:3]\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3])\n",
    "    \n",
    "    return pred_labels, row_ids, pred_probas\n",
    "    \n",
    "    \n",
    "def process_grid(df_train, df_test, th, n_cells):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results and makes the\n",
    "    submission.\n",
    "    \"\"\" \n",
    "    preds = np.zeros((df_test.shape[0], 3), dtype=int)\n",
    "    pred_probability = np.zeros((df_test.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for g_id in range(n_cells):\n",
    "        if g_id % 25 == 0:\n",
    "            print('iter: %s' %(g_id))\n",
    "        \n",
    "        #Applying classifier to one grid cell\n",
    "        pred_labels, row_ids, pred_probas = process_one_cell(df_train, df_test, g_id, th)\n",
    "\n",
    "        #Updating predictions\n",
    "        preds[row_ids] = pred_labels\n",
    "        pred_probability[row_ids] = pred_probas\n",
    "\n",
    "    print('Generating submission file ...')\n",
    "    #Auxiliary dataframe with the 3 best predictions for each sample\n",
    "    df_preds = pd.DataFrame(preds, columns=['l1', 'l2', 'l3'])\n",
    "    df_probas = pd.DataFrame(pred_probability, columns=['l1', 'l2', 'l3'])\n",
    "    \n",
    "    return df_preds, df_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Preparing train data\n",
      "Preparing test data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "print('Loading data ...')\n",
    "df_train = pd.read_hdf('train.h5','table')\n",
    "df_test = pd.read_hdf('test.h5','table')\n",
    "\n",
    "#Defining the size of the grid\n",
    "n_cell_x = 20\n",
    "n_cell_y = 40 \n",
    "\n",
    "print('Preparing train data')\n",
    "#df_train = prepare_data(df_train, n_cell_x, n_cell_y)\n",
    "\n",
    "print('Preparing test data')\n",
    "#df_test = prepare_data(df_test, n_cell_x, n_cell_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "iter: 25\n",
      "iter: 50\n",
      "iter: 75\n",
      "iter: 100\n",
      "iter: 125\n",
      "iter: 150\n",
      "iter: 175\n",
      "iter: 200\n",
      "iter: 225\n",
      "iter: 250\n",
      "iter: 275\n",
      "iter: 300\n",
      "iter: 325\n",
      "iter: 350\n",
      "iter: 375\n",
      "iter: 400\n",
      "iter: 425\n",
      "iter: 450\n",
      "iter: 475\n",
      "iter: 500\n",
      "iter: 525\n",
      "iter: 550\n",
      "iter: 575\n",
      "iter: 600\n",
      "iter: 625\n",
      "iter: 650\n",
      "iter: 675\n",
      "iter: 700\n",
      "iter: 725\n",
      "iter: 750\n",
      "iter: 775\n",
      "Generating submission file ...\n"
     ]
    }
   ],
   "source": [
    "#Solving classification problems inside each grid cell\n",
    "th = 5 #Keeping place_ids with more than th samples.   \n",
    "prediction, probability = process_grid(df_train, df_test, th, n_cell_x*n_cell_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8607230, 3), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape,type(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8607230, 3), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.shape,type(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.308713</td>\n",
       "      <td>0.154834</td>\n",
       "      <td>0.137801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242668</td>\n",
       "      <td>0.151991</td>\n",
       "      <td>0.116748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.394223</td>\n",
       "      <td>0.278302</td>\n",
       "      <td>0.110240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.665965</td>\n",
       "      <td>0.166739</td>\n",
       "      <td>0.048985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.876901</td>\n",
       "      <td>0.087552</td>\n",
       "      <td>0.035546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2        l3\n",
       "0  0.308713  0.154834  0.137801\n",
       "1  0.242668  0.151991  0.116748\n",
       "2  0.394223  0.278302  0.110240\n",
       "3  0.665965  0.166739  0.048985\n",
       "4  0.876901  0.087552  0.035546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_hdf('1234predictedplaces.h5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability.to_hdf('1234predictedprobability.h5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
